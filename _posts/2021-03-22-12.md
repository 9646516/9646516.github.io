最近在做一些文字检测的东西,现在一通爆卷的模型识别到的是文字的充分条件,还是必要条件中的一个子集?

现在的模型在简单场景下的效果已经很不错了。遇到的问题主要还是几个老生常谈的问题。想要解决这些问题，现在看起来还是需要新的工具。现在这么多方法，其实还是不能解决这几个老问题。

文字和普通的目标最大的区别就是，一般的目标长宽比几乎不变,而且有特征部分方便模型定位。文字理论上想多长就多长，而且形状方向多变。如果不考虑文字本身的特征其实是可以做的,但是这样会导致理论上完美的模型会非常复杂,很难训练得到完美的模型。

当然如果是企业,只需要堆显卡和用户数据上去就可以解决问题。但是如果想解决这个问题的话,要么是用各种模型拟合文字，降低模型的复杂度。要么是针对现在模型难以训练的问题，用多阶段的方法，降低模型的误差。有没有可能从文字本身的特征出发，针对特征本身训练模型?

旷视的某篇论文显然是借鉴了微软当年的文章，虽然文章里面只字未提，但是显然是借鉴了传统方法中对文字特性的考察。但是从这里也可以看出，想要结合传统方法也是很难的。这篇文章没有使用原方法基于笔画的特征，而是使用了基于文本块的方法。传统方法是基于手工特征的经验方法，而现在使用的都是高层特征。如果使用了低层次的特征，最大的问题还是低层次特征对原图像的损失太大。

此外不包含语言知识的模型真的可以正确识别出文字吗。其实这个问题也是挺显然的,因为有些图案和文字几乎没有区别,人类之所以能区分开是否是文字是因为掌握了语言知识。此外还有艺术字,仅仅靠文字特征十分容易漏检。CVPR 2021有篇文章就说了这个事情。

接下来的问题就是现在这种一通爆卷的模型可以胜任这个任务吗。显然最开始的阶段卷是必要的，这样可以提取出梯度上的一些特征，这个和人类识别图片的过程是类似的。但是接下来的阶段只靠卷积足够吗。虽然FCN一直用到今天都没什么问题,但是不可否认的是训练难度非常大,GPU少的条件下根本训练不出来能用的模型。

最后的问题是分割模型进度低的问题,现在的字越来越小,原来的模型越来越不够用。如果不用分割的话,靠bounding box回归的话,前人的经验表明旋转并不靠谱,怎么生成倾斜的box也许是思考的方向。