---
layout: post
title: "随想2"
categories:
  - Category
---

随着调研的深入,我越来越觉得文本检测在现在也就这样了,原因很简单,文本检测的瓶颈还是一般检测任务的瓶颈,虽然现在新方法这么多,但是还没有重大突破。

此外这个任务本身就是反直觉的,人识字显然是从高频分量入手,但是现在的做法确实在字的外面画个框,去拟合一个找框的函数。此外还有一堆老大难问题,随便想想就能想到不少问题。

anchor based的方法无法解决不规则的文字,如果直接回归四个点坐标或者4+1,计算都慢到无法忍受,之前的方法之所以可以忍受是应为竖直矩形框计算IOU可以SIMD,但不规则文本框几乎做不到SIMD。此外还有anchor自己的问题,比如调参数困难之类的。我觉得除非硬件条件跟上去了,用的八路可扩展Xeon外加3090插满,或者有办法不算IOU了,用anchor解决凸多边形问题还是有点难。

如果不用anchor,不知道你知不知道为什么现在实际用的EAST都是只用了RBOX,几乎没看到有人用QUAD?问题还是和上面一样,计算IOU或者说是把预测和truth匹配困难。此外还有一个问题,回归的时候到底对谁回归,如果这里写死的话是不是无法自适应不同大小的输入?

这么看来分割的方法也许会好一点,但是分割的问题也不少。首先是一个点可能属于两个文本块,也就是说文本会有重合的问题,这个问题几乎解决不了。此外还有分割精度跟不上的问题,小的字还要用检测来打补丁。此外文字会有嵌套,现在只能靠PSENET这种从小到大的检测方法解决。

总之问题的根源就是现在的任务本身就是反直觉的,同时高精度数据集少,解决问题的办法估计只有大力出奇迹,堆数据和显卡再难的问题也能解决

我比较欣赏的方法是SWT这种基于文本特征的方法,但是在现在看来似乎不太适合深度学习,哪怕像textSnake和textField这些模仿者也不是基于文字的,而是基于文本块的。
